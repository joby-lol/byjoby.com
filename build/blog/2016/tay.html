<!DOCTYPE html>
<html>
<head>
    <title>Tay, racist AI, and the limitations of geeks :: Joby Elliott</title>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <meta name="theme-color" content="#C42F1E">
    <link rel="stylesheet" href="/style.css">
</head>
<body>

<header>
    <h1>(*joby_elliott).blog</h1>
</header>
<nav>
    <a href="/blog/" class="active">Blog</a>
    <a href="/cv/">CV</a>
</nav>

<div id="content">

<h1 id="tay-racist-ai-and-the-limitations-of-geeks">Tay, racist AI, and the limitations of geeks</h1>
<p><a href="http://www.buzzfeed.com/alexkantrowitz/how-the-internet-turned-microsofts-ai-chatbot-into-a-neo-naz#.kve91X6m9">Tay was certainly a mess for Microsoft</a> (although everyone does now know that they’re building halfway decent chatterbots, so that’s maybe a PR win). The whole fiasco reminds me of the time like a year ago when Google Photos’ auto-tagging was <a href="http://mashable.com/2015/07/01/google-photos-black-people-gorillas/">tagging black people as gorillas</a>, or otherwise as animals.</p>
<p>This time, with Microsoft, the response has been pretty even-keeled. Nobody seems to really think Microsoft themselves are racists, or holocaust deniers, or actually onboard with any of the other noxious crap Tay learned from Twitter.  Google wasn’t so lucky. I remember a decent number of people responding as if Google themselves were actually secretly racist, and this was just it sneaking out into public.</p>
<p>In situations like this, though, we have to remember that these machine-learning systems aren’t really inherently anything-ist. They’re just learning whatever we train them. Tay the chatterbot isn’t racist. I’m pretty sure it’s not even doing anything that could be considered real understanding, and so is kind of incapable of actually being a racist.</p>
<p>That’s the hard part of a learning machine: teaching it. It’s going to faithfully absorb everything in that training data. If you train an image classifier from tags on the internet? It’s going to be as racist and terrible as the internet and the people on it, which is to say often pretty <a href="http://4chan.org/">racist</a> and <a href="http://www.godhatesfags.com/">terrible</a>. If you train it from Twitter it’s going to be as vicious, racist, and unpleasant as Twitter, which is often pretty <a href="https://twitter.com/realDonaldTrump">vicious, racist, and unpleasant</a>.</p>
<p>I’ve thought about this a lot lately, and I’m pretty sure that it’s going to take years and years of hands-on training from humans to produce AIs that are decent. Building them will only be half the battle — then we have to raise them. These aren’t straightforward human-conceivable algorithms any more where we can just think through how it’s going to work. Once a neural net is trained, we don’t even know exactly how it works — just that it now does.</p>
<p>Even once we nerds build the things, I think we’re going to have to admit that we’re maybe not the best ones to actually guide their development. There’s going to come a time for us to hand it off to the people like my girlfriend and mother — teachers, artists, developmental specialists. The higher-level training stages <em>might not actually be a job for us.</em></p>


</div>

</body>
</html>

<!--
File data:
last modified: Tue Apr 05 2016 19:19:36 GMT-0600 (Mountain Daylight Time)
last built: Tue Apr 05 2016 19:19:47 GMT-0600 (Mountain Daylight Time)
-->
